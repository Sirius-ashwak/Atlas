{
  "experiment": "Efficient_GAT_Real_Data",
  "date": "2025-10-07T20:18:02.628894",
  "data_source": "IOT-temp.csv (sampled)",
  "sample_size": 5000,
  "num_graphs": 100,
  "best_reward": 43.90202226638794,
  "improvement_percent": -82.15510029006262,
  "model_params": 1833,
  "results": [
    {
      "epoch": 0,
      "train_loss": 4697.770903199911,
      "val_loss": 5434.34181728363,
      "val_reward": 28.72827147245407
    },
    {
      "epoch": 1,
      "train_loss": 902.4895982724614,
      "val_loss": 5059.323287391662,
      "val_reward": 29.897992873191832
    },
    {
      "epoch": 2,
      "train_loss": 975.9942401496876,
      "val_loss": 6612.13288269043,
      "val_reward": 17.57066879272461
    },
    {
      "epoch": 3,
      "train_loss": 785.9771435260773,
      "val_loss": 5298.837316894531,
      "val_reward": 31.433960962295533
    },
    {
      "epoch": 4,
      "train_loss": 787.790360683389,
      "val_loss": 5666.070929479599,
      "val_reward": 25.526073837280272
    },
    {
      "epoch": 5,
      "train_loss": 1045.87001468628,
      "val_loss": 5994.315995788575,
      "val_reward": 22.138459348678587
    },
    {
      "epoch": 6,
      "train_loss": 1106.3921126106638,
      "val_loss": 4943.397988891602,
      "val_reward": 28.72247395515442
    },
    {
      "epoch": 7,
      "train_loss": 1102.058155230817,
      "val_loss": 4479.432434272766,
      "val_reward": 33.392774391174314
    },
    {
      "epoch": 8,
      "train_loss": 1493.2065270006656,
      "val_loss": 5455.765880703926,
      "val_reward": 26.962086486816407
    },
    {
      "epoch": 9,
      "train_loss": 1046.5285123518552,
      "val_loss": 4636.963016891479,
      "val_reward": 31.90472230911255
    },
    {
      "epoch": 10,
      "train_loss": 768.7019348845118,
      "val_loss": 5614.740709590912,
      "val_reward": 26.652993202209473
    },
    {
      "epoch": 11,
      "train_loss": 982.879130846262,
      "val_loss": 5599.089679357409,
      "val_reward": 26.363691425323488
    },
    {
      "epoch": 12,
      "train_loss": 1283.81480172507,
      "val_loss": 5166.992311155796,
      "val_reward": 29.49035487174988
    },
    {
      "epoch": 13,
      "train_loss": 859.1684552036226,
      "val_loss": 4912.213334143162,
      "val_reward": 30.610523223876953
    },
    {
      "epoch": 14,
      "train_loss": 625.4975057777017,
      "val_loss": 4725.4072937011715,
      "val_reward": 38.60645895004272
    },
    {
      "epoch": 15,
      "train_loss": 1190.8659831151367,
      "val_loss": 4993.142893981933,
      "val_reward": 28.811058855056764
    },
    {
      "epoch": 16,
      "train_loss": 725.5307615092206,
      "val_loss": 4465.670861816407,
      "val_reward": 32.02639012336731
    },
    {
      "epoch": 17,
      "train_loss": 876.6638624649495,
      "val_loss": 4072.58313293457,
      "val_reward": 40.79414358139038
    },
    {
      "epoch": 18,
      "train_loss": 1325.74675334841,
      "val_loss": 3695.2274754047394,
      "val_reward": 39.728267192840576
    },
    {
      "epoch": 19,
      "train_loss": 605.570098240301,
      "val_loss": 4162.351269942522,
      "val_reward": 35.989853096008304
    },
    {
      "epoch": 20,
      "train_loss": 1060.6718766152858,
      "val_loss": 4298.0000297546385,
      "val_reward": 36.87420625686646
    },
    {
      "epoch": 21,
      "train_loss": 844.9152020579204,
      "val_loss": 3744.80082321167,
      "val_reward": 41.26749725341797
    },
    {
      "epoch": 22,
      "train_loss": 808.7833068749867,
      "val_loss": 3830.2166662693026,
      "val_reward": 40.06272287368775
    },
    {
      "epoch": 23,
      "train_loss": 1223.507631598413,
      "val_loss": 4015.149927636981,
      "val_reward": 37.11623115539551
    },
    {
      "epoch": 24,
      "train_loss": 858.058606368117,
      "val_loss": 4186.194251912832,
      "val_reward": 35.68507661819458
    },
    {
      "epoch": 25,
      "train_loss": 664.2822681736434,
      "val_loss": 4445.971898794174,
      "val_reward": 33.663069820404054
    },
    {
      "epoch": 26,
      "train_loss": 893.8347842508956,
      "val_loss": 4352.8600125312805,
      "val_reward": 35.41475763320923
    },
    {
      "epoch": 27,
      "train_loss": 875.4673825619742,
      "val_loss": 3638.1573932647707,
      "val_reward": 42.30988907814026
    },
    {
      "epoch": 28,
      "train_loss": 604.4505650055595,
      "val_loss": 4648.010618543625,
      "val_reward": 32.43442316055298
    },
    {
      "epoch": 29,
      "train_loss": 946.0201619939878,
      "val_loss": 3896.085246658325,
      "val_reward": 40.35204954147339
    },
    {
      "epoch": 30,
      "train_loss": 685.3092835400254,
      "val_loss": 4324.554375499487,
      "val_reward": 35.35719561576843
    },
    {
      "epoch": 31,
      "train_loss": 489.5398419384816,
      "val_loss": 4527.931085062027,
      "val_reward": 33.53376407623291
    },
    {
      "epoch": 32,
      "train_loss": 534.0694612164982,
      "val_loss": 4706.698290443421,
      "val_reward": 32.22922973632812
    },
    {
      "epoch": 33,
      "train_loss": 594.2707795992494,
      "val_loss": 4956.887355041504,
      "val_reward": 28.48053822517395
    },
    {
      "epoch": 34,
      "train_loss": 907.0281850028783,
      "val_loss": 4586.108401298523,
      "val_reward": 32.82856249809265
    },
    {
      "epoch": 35,
      "train_loss": 1022.7917532313616,
      "val_loss": 4377.752706909179,
      "val_reward": 32.36768026351929
    },
    {
      "epoch": 36,
      "train_loss": 652.8560426920885,
      "val_loss": 3330.5326551352628,
      "val_reward": 43.90202226638794
    },
    {
      "epoch": 37,
      "train_loss": 1023.256833351031,
      "val_loss": 4071.8163719654085,
      "val_reward": 36.78775691986084
    },
    {
      "epoch": 38,
      "train_loss": 755.4848894720897,
      "val_loss": 4089.549905014038,
      "val_reward": 38.13625907897949
    },
    {
      "epoch": 39,
      "train_loss": 841.9031096650288,
      "val_loss": 3947.6372093200685,
      "val_reward": 38.65972690582275
    },
    {
      "epoch": 40,
      "train_loss": 941.9266257047653,
      "val_loss": 4313.621608734131,
      "val_reward": 33.681438541412355
    },
    {
      "epoch": 41,
      "train_loss": 618.3370247366227,
      "val_loss": 4362.599911212921,
      "val_reward": 35.55367546081543
    },
    {
      "epoch": 42,
      "train_loss": 670.7923203786835,
      "val_loss": 4519.408073693514,
      "val_reward": 33.936135864257814
    },
    {
      "epoch": 43,
      "train_loss": 795.3964465810452,
      "val_loss": 4743.650331439171,
      "val_reward": 32.06582469940186
    },
    {
      "epoch": 44,
      "train_loss": 492.970471491362,
      "val_loss": 4514.728352275491,
      "val_reward": 34.30085515975952
    },
    {
      "epoch": 45,
      "train_loss": 748.2503170246258,
      "val_loss": 4534.153519821167,
      "val_reward": 32.519058799743654
    },
    {
      "epoch": 46,
      "train_loss": 749.0335225805641,
      "val_loss": 4426.938184785843,
      "val_reward": 34.86882753372193
    },
    {
      "epoch": 47,
      "train_loss": 733.8097318479907,
      "val_loss": 4159.30647215388,
      "val_reward": 36.50982475280762
    },
    {
      "epoch": 48,
      "train_loss": 693.9384340472286,
      "val_loss": 4269.735000610352,
      "val_reward": 39.07130823135376
    },
    {
      "epoch": 49,
      "train_loss": 683.5260948006304,
      "val_loss": 4628.255606079101,
      "val_reward": 30.68086462020874
    }
  ]
}