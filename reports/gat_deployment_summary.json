{
  "gat_deployment_summary": {
    "date": "2025-10-07T20:25:33.407416",
    "status": "GAT_MODELS_TRAINED",
    "experiments_completed": 2,
    "models_available": [
      "models/phase3_gat/simple_gat_best.pt",
      "models/phase3_gat/efficient_gat_best.pt"
    ]
  },
  "performance_comparison": {
    "gcn_baseline": {
      "reward": 246.02,
      "std": 8.57,
      "model_path": "models/hybrid/best_model.pt",
      "status": "production"
    },
    "gat_results": {
      "Simple_GAT_Training": {
        "reward": 207.41639251708983,
        "improvement_percent": -15.691247655845125,
        "model_params": 17280,
        "training_date": "2025-10-07T19:43:01.344663"
      },
      "Efficient_GAT_Real_Data": {
        "reward": 43.90202226638794,
        "improvement_percent": -82.15510029006262,
        "model_params": 1833,
        "training_date": "2025-10-07T20:18:02.628894"
      }
    }
  },
  "experiments": {
    "Simple_GAT_Training": {
      "experiment": "Simple_GAT_Training",
      "date": "2025-10-07T19:43:01.344663",
      "best_reward": 207.41639251708983,
      "improvement_percent": -15.691247655845125,
      "epochs": 100,
      "model_params": 17280,
      "results": [
        {
          "epoch": 0,
          "reward": 196.82496185302733,
          "loss": 38855.366015625
        },
        {
          "epoch": 1,
          "reward": 197.95291442871093,
          "loss": 39216.36640625
        },
        {
          "epoch": 2,
          "reward": 201.57378082275392,
          "loss": 40704.95703125
        },
        {
          "epoch": 3,
          "reward": 201.86080169677734,
          "loss": 40787.7078125
        },
        {
          "epoch": 4,
          "reward": 202.44539337158204,
          "loss": 41068.6609375
        },
        {
          "epoch": 5,
          "reward": 201.42797088623047,
          "loss": 40607.681640625
        },
        {
          "epoch": 6,
          "reward": 202.96955261230468,
          "loss": 41284.71328125
        },
        {
          "epoch": 7,
          "reward": 201.09628448486328,
          "loss": 40575.9619140625
        },
        {
          "epoch": 8,
          "reward": 204.25469360351562,
          "loss": 41759.881640625
        },
        {
          "epoch": 9,
          "reward": 204.13079986572265,
          "loss": 41713.68828125
        },
        {
          "epoch": 10,
          "reward": 197.16358795166016,
          "loss": 38980.7728515625
        },
        {
          "epoch": 11,
          "reward": 200.8962829589844,
          "loss": 40426.9515625
        },
        {
          "epoch": 12,
          "reward": 205.88372192382812,
          "loss": 42432.827734375
        },
        {
          "epoch": 13,
          "reward": 204.82589874267578,
          "loss": 42000.51796875
        },
        {
          "epoch": 14,
          "reward": 200.96141357421874,
          "loss": 40452.891015625
        },
        {
          "epoch": 15,
          "reward": 201.19752502441406,
          "loss": 40489.49296875
        },
        {
          "epoch": 16,
          "reward": 198.41270599365234,
          "loss": 39430.8984375
        },
        {
          "epoch": 17,
          "reward": 192.9933074951172,
          "loss": 37210.195703125
        },
        {
          "epoch": 18,
          "reward": 198.87112579345703,
          "loss": 39499.88359375
        },
        {
          "epoch": 19,
          "reward": 204.08231201171876,
          "loss": 40864.72109375
        },
        {
          "epoch": 20,
          "reward": 199.11939086914063,
          "loss": 39533.83046875
        },
        {
          "epoch": 21,
          "reward": 199.1249206542969,
          "loss": 39441.12734375
        },
        {
          "epoch": 22,
          "reward": 204.09317932128906,
          "loss": 41437.35390625
        },
        {
          "epoch": 23,
          "reward": 201.22118682861327,
          "loss": 39442.224609375
        },
        {
          "epoch": 24,
          "reward": 199.40140380859376,
          "loss": 38632.9482421875
        },
        {
          "epoch": 25,
          "reward": 201.5699722290039,
          "loss": 40117.653515625
        },
        {
          "epoch": 26,
          "reward": 198.15091247558593,
          "loss": 38555.916796875
        },
        {
          "epoch": 27,
          "reward": 197.79371185302733,
          "loss": 38053.656640625
        },
        {
          "epoch": 28,
          "reward": 200.78115234375,
          "loss": 36512.0630859375
        },
        {
          "epoch": 29,
          "reward": 197.47791442871093,
          "loss": 34206.5296875
        },
        {
          "epoch": 30,
          "reward": 197.88221282958983,
          "loss": 36974.1685546875
        },
        {
          "epoch": 31,
          "reward": 200.79139862060546,
          "loss": 38253.994140625
        },
        {
          "epoch": 32,
          "reward": 202.61507263183594,
          "loss": 35992.4384765625
        },
        {
          "epoch": 33,
          "reward": 198.09615936279297,
          "loss": 34795.30302734375
        },
        {
          "epoch": 34,
          "reward": 203.324755859375,
          "loss": 34923.64384765625
        },
        {
          "epoch": 35,
          "reward": 199.27930603027343,
          "loss": 21800.088916015626
        },
        {
          "epoch": 36,
          "reward": 197.60973052978517,
          "loss": 25875.08984375
        },
        {
          "epoch": 37,
          "reward": 198.04579467773436,
          "loss": 23122.18291015625
        },
        {
          "epoch": 38,
          "reward": 196.53489990234374,
          "loss": 53803.71964111328
        },
        {
          "epoch": 39,
          "reward": 203.37404174804686,
          "loss": 27520.87041015625
        },
        {
          "epoch": 40,
          "reward": 198.0280029296875,
          "loss": 28869.1822265625
        },
        {
          "epoch": 41,
          "reward": 196.74410247802734,
          "loss": 22933.212329101563
        },
        {
          "epoch": 42,
          "reward": 195.34676513671874,
          "loss": 26000.545458984376
        },
        {
          "epoch": 43,
          "reward": 199.06099548339844,
          "loss": 29471.94150390625
        },
        {
          "epoch": 44,
          "reward": 198.0695571899414,
          "loss": 28869.584094238282
        },
        {
          "epoch": 45,
          "reward": 198.26205444335938,
          "loss": 25479.24372215271
        },
        {
          "epoch": 46,
          "reward": 204.47887573242187,
          "loss": 24373.06301269531
        },
        {
          "epoch": 47,
          "reward": 199.74862365722657,
          "loss": 27301.15537109375
        },
        {
          "epoch": 48,
          "reward": 207.41639251708983,
          "loss": 34314.251782226565
        },
        {
          "epoch": 49,
          "reward": 198.11011352539063,
          "loss": 29925.915234375
        },
        {
          "epoch": 50,
          "reward": 197.79098205566407,
          "loss": 27624.974658203126
        },
        {
          "epoch": 51,
          "reward": 198.02256622314454,
          "loss": 28652.75966796875
        },
        {
          "epoch": 52,
          "reward": 201.1893798828125,
          "loss": 33325.266015625
        },
        {
          "epoch": 53,
          "reward": 203.67650299072267,
          "loss": 29068.968212890624
        },
        {
          "epoch": 54,
          "reward": 199.54358367919923,
          "loss": 31728.8009765625
        },
        {
          "epoch": 55,
          "reward": 201.18322143554687,
          "loss": 31101.591552734375
        },
        {
          "epoch": 56,
          "reward": 200.42754974365235,
          "loss": 30716.019580078126
        },
        {
          "epoch": 57,
          "reward": 200.74215087890624,
          "loss": 31472.811328125
        },
        {
          "epoch": 58,
          "reward": 198.6973907470703,
          "loss": 28950.89973144531
        },
        {
          "epoch": 59,
          "reward": 196.5137176513672,
          "loss": 36063.7533203125
        },
        {
          "epoch": 60,
          "reward": 203.39111785888673,
          "loss": 30335.89716796875
        },
        {
          "epoch": 61,
          "reward": 201.6266311645508,
          "loss": 32656.72578125
        },
        {
          "epoch": 62,
          "reward": 191.1313018798828,
          "loss": 25886.84970703125
        },
        {
          "epoch": 63,
          "reward": 205.14222259521483,
          "loss": 32139.3126953125
        },
        {
          "epoch": 64,
          "reward": 199.70751037597657,
          "loss": 33173.6375
        },
        {
          "epoch": 65,
          "reward": 197.91238250732422,
          "loss": 29435.4853515625
        },
        {
          "epoch": 66,
          "reward": 201.80557556152343,
          "loss": 32203.61875
        },
        {
          "epoch": 67,
          "reward": 198.31324462890626,
          "loss": 29610.37412109375
        },
        {
          "epoch": 68,
          "reward": 201.0832748413086,
          "loss": 31817.69150390625
        },
        {
          "epoch": 69,
          "reward": 195.64273834228516,
          "loss": 25682.212060546874
        },
        {
          "epoch": 70,
          "reward": 205.6271942138672,
          "loss": 26313.878955078126
        },
        {
          "epoch": 71,
          "reward": 201.37761840820312,
          "loss": 28309.9923828125
        },
        {
          "epoch": 72,
          "reward": 199.18597259521485,
          "loss": 21582.31101074219
        },
        {
          "epoch": 73,
          "reward": 204.60651092529298,
          "loss": 28916.2380859375
        },
        {
          "epoch": 74,
          "reward": 194.03451080322264,
          "loss": 20184.263153076172
        },
        {
          "epoch": 75,
          "reward": 196.11755981445313,
          "loss": 29238.63291015625
        },
        {
          "epoch": 76,
          "reward": 195.64547576904297,
          "loss": 20204.26591796875
        },
        {
          "epoch": 77,
          "reward": 200.70952453613282,
          "loss": 26388.518505859374
        },
        {
          "epoch": 78,
          "reward": 199.24020385742188,
          "loss": 27800.48399810791
        },
        {
          "epoch": 79,
          "reward": 198.25562896728516,
          "loss": 21332.245458984376
        },
        {
          "epoch": 80,
          "reward": 204.34351196289063,
          "loss": 13136.709146118164
        },
        {
          "epoch": 81,
          "reward": 197.26844482421876,
          "loss": 28517.72919921875
        },
        {
          "epoch": 82,
          "reward": 199.26383056640626,
          "loss": 24693.58794133663
        },
        {
          "epoch": 83,
          "reward": 203.10350036621094,
          "loss": 25151.26494140625
        },
        {
          "epoch": 84,
          "reward": 202.87717895507814,
          "loss": 23970.84404296875
        },
        {
          "epoch": 85,
          "reward": 195.49026489257812,
          "loss": 39183.14580078125
        },
        {
          "epoch": 86,
          "reward": 204.45771179199218,
          "loss": 27794.14599609375
        },
        {
          "epoch": 87,
          "reward": 200.74012451171876,
          "loss": 21611.352160644532
        },
        {
          "epoch": 88,
          "reward": 204.09170837402343,
          "loss": 28864.751953125
        },
        {
          "epoch": 89,
          "reward": 194.42381286621094,
          "loss": 31506.215234375
        },
        {
          "epoch": 90,
          "reward": 205.49867248535156,
          "loss": 27687.58501586914
        },
        {
          "epoch": 91,
          "reward": 199.15196075439454,
          "loss": 27790.78955078125
        },
        {
          "epoch": 92,
          "reward": 200.88705291748047,
          "loss": 30144.15595703125
        },
        {
          "epoch": 93,
          "reward": 203.80834045410157,
          "loss": 30577.973046875
        },
        {
          "epoch": 94,
          "reward": 203.1804428100586,
          "loss": 28042.559521484374
        },
        {
          "epoch": 95,
          "reward": 201.56673126220704,
          "loss": 30455.499609375
        },
        {
          "epoch": 96,
          "reward": 204.34564361572265,
          "loss": 28688.32700996399
        },
        {
          "epoch": 97,
          "reward": 198.59858093261718,
          "loss": 29783.07998046875
        },
        {
          "epoch": 98,
          "reward": 198.4001007080078,
          "loss": 24401.020967388155
        },
        {
          "epoch": 99,
          "reward": 196.81157684326172,
          "loss": 29866.8287109375
        }
      ]
    },
    "Efficient_GAT_Real_Data": {
      "experiment": "Efficient_GAT_Real_Data",
      "date": "2025-10-07T20:18:02.628894",
      "data_source": "IOT-temp.csv (sampled)",
      "sample_size": 5000,
      "num_graphs": 100,
      "best_reward": 43.90202226638794,
      "improvement_percent": -82.15510029006262,
      "model_params": 1833,
      "results": [
        {
          "epoch": 0,
          "train_loss": 4697.770903199911,
          "val_loss": 5434.34181728363,
          "val_reward": 28.72827147245407
        },
        {
          "epoch": 1,
          "train_loss": 902.4895982724614,
          "val_loss": 5059.323287391662,
          "val_reward": 29.897992873191832
        },
        {
          "epoch": 2,
          "train_loss": 975.9942401496876,
          "val_loss": 6612.13288269043,
          "val_reward": 17.57066879272461
        },
        {
          "epoch": 3,
          "train_loss": 785.9771435260773,
          "val_loss": 5298.837316894531,
          "val_reward": 31.433960962295533
        },
        {
          "epoch": 4,
          "train_loss": 787.790360683389,
          "val_loss": 5666.070929479599,
          "val_reward": 25.526073837280272
        },
        {
          "epoch": 5,
          "train_loss": 1045.87001468628,
          "val_loss": 5994.315995788575,
          "val_reward": 22.138459348678587
        },
        {
          "epoch": 6,
          "train_loss": 1106.3921126106638,
          "val_loss": 4943.397988891602,
          "val_reward": 28.72247395515442
        },
        {
          "epoch": 7,
          "train_loss": 1102.058155230817,
          "val_loss": 4479.432434272766,
          "val_reward": 33.392774391174314
        },
        {
          "epoch": 8,
          "train_loss": 1493.2065270006656,
          "val_loss": 5455.765880703926,
          "val_reward": 26.962086486816407
        },
        {
          "epoch": 9,
          "train_loss": 1046.5285123518552,
          "val_loss": 4636.963016891479,
          "val_reward": 31.90472230911255
        },
        {
          "epoch": 10,
          "train_loss": 768.7019348845118,
          "val_loss": 5614.740709590912,
          "val_reward": 26.652993202209473
        },
        {
          "epoch": 11,
          "train_loss": 982.879130846262,
          "val_loss": 5599.089679357409,
          "val_reward": 26.363691425323488
        },
        {
          "epoch": 12,
          "train_loss": 1283.81480172507,
          "val_loss": 5166.992311155796,
          "val_reward": 29.49035487174988
        },
        {
          "epoch": 13,
          "train_loss": 859.1684552036226,
          "val_loss": 4912.213334143162,
          "val_reward": 30.610523223876953
        },
        {
          "epoch": 14,
          "train_loss": 625.4975057777017,
          "val_loss": 4725.4072937011715,
          "val_reward": 38.60645895004272
        },
        {
          "epoch": 15,
          "train_loss": 1190.8659831151367,
          "val_loss": 4993.142893981933,
          "val_reward": 28.811058855056764
        },
        {
          "epoch": 16,
          "train_loss": 725.5307615092206,
          "val_loss": 4465.670861816407,
          "val_reward": 32.02639012336731
        },
        {
          "epoch": 17,
          "train_loss": 876.6638624649495,
          "val_loss": 4072.58313293457,
          "val_reward": 40.79414358139038
        },
        {
          "epoch": 18,
          "train_loss": 1325.74675334841,
          "val_loss": 3695.2274754047394,
          "val_reward": 39.728267192840576
        },
        {
          "epoch": 19,
          "train_loss": 605.570098240301,
          "val_loss": 4162.351269942522,
          "val_reward": 35.989853096008304
        },
        {
          "epoch": 20,
          "train_loss": 1060.6718766152858,
          "val_loss": 4298.0000297546385,
          "val_reward": 36.87420625686646
        },
        {
          "epoch": 21,
          "train_loss": 844.9152020579204,
          "val_loss": 3744.80082321167,
          "val_reward": 41.26749725341797
        },
        {
          "epoch": 22,
          "train_loss": 808.7833068749867,
          "val_loss": 3830.2166662693026,
          "val_reward": 40.06272287368775
        },
        {
          "epoch": 23,
          "train_loss": 1223.507631598413,
          "val_loss": 4015.149927636981,
          "val_reward": 37.11623115539551
        },
        {
          "epoch": 24,
          "train_loss": 858.058606368117,
          "val_loss": 4186.194251912832,
          "val_reward": 35.68507661819458
        },
        {
          "epoch": 25,
          "train_loss": 664.2822681736434,
          "val_loss": 4445.971898794174,
          "val_reward": 33.663069820404054
        },
        {
          "epoch": 26,
          "train_loss": 893.8347842508956,
          "val_loss": 4352.8600125312805,
          "val_reward": 35.41475763320923
        },
        {
          "epoch": 27,
          "train_loss": 875.4673825619742,
          "val_loss": 3638.1573932647707,
          "val_reward": 42.30988907814026
        },
        {
          "epoch": 28,
          "train_loss": 604.4505650055595,
          "val_loss": 4648.010618543625,
          "val_reward": 32.43442316055298
        },
        {
          "epoch": 29,
          "train_loss": 946.0201619939878,
          "val_loss": 3896.085246658325,
          "val_reward": 40.35204954147339
        },
        {
          "epoch": 30,
          "train_loss": 685.3092835400254,
          "val_loss": 4324.554375499487,
          "val_reward": 35.35719561576843
        },
        {
          "epoch": 31,
          "train_loss": 489.5398419384816,
          "val_loss": 4527.931085062027,
          "val_reward": 33.53376407623291
        },
        {
          "epoch": 32,
          "train_loss": 534.0694612164982,
          "val_loss": 4706.698290443421,
          "val_reward": 32.22922973632812
        },
        {
          "epoch": 33,
          "train_loss": 594.2707795992494,
          "val_loss": 4956.887355041504,
          "val_reward": 28.48053822517395
        },
        {
          "epoch": 34,
          "train_loss": 907.0281850028783,
          "val_loss": 4586.108401298523,
          "val_reward": 32.82856249809265
        },
        {
          "epoch": 35,
          "train_loss": 1022.7917532313616,
          "val_loss": 4377.752706909179,
          "val_reward": 32.36768026351929
        },
        {
          "epoch": 36,
          "train_loss": 652.8560426920885,
          "val_loss": 3330.5326551352628,
          "val_reward": 43.90202226638794
        },
        {
          "epoch": 37,
          "train_loss": 1023.256833351031,
          "val_loss": 4071.8163719654085,
          "val_reward": 36.78775691986084
        },
        {
          "epoch": 38,
          "train_loss": 755.4848894720897,
          "val_loss": 4089.549905014038,
          "val_reward": 38.13625907897949
        },
        {
          "epoch": 39,
          "train_loss": 841.9031096650288,
          "val_loss": 3947.6372093200685,
          "val_reward": 38.65972690582275
        },
        {
          "epoch": 40,
          "train_loss": 941.9266257047653,
          "val_loss": 4313.621608734131,
          "val_reward": 33.681438541412355
        },
        {
          "epoch": 41,
          "train_loss": 618.3370247366227,
          "val_loss": 4362.599911212921,
          "val_reward": 35.55367546081543
        },
        {
          "epoch": 42,
          "train_loss": 670.7923203786835,
          "val_loss": 4519.408073693514,
          "val_reward": 33.936135864257814
        },
        {
          "epoch": 43,
          "train_loss": 795.3964465810452,
          "val_loss": 4743.650331439171,
          "val_reward": 32.06582469940186
        },
        {
          "epoch": 44,
          "train_loss": 492.970471491362,
          "val_loss": 4514.728352275491,
          "val_reward": 34.30085515975952
        },
        {
          "epoch": 45,
          "train_loss": 748.2503170246258,
          "val_loss": 4534.153519821167,
          "val_reward": 32.519058799743654
        },
        {
          "epoch": 46,
          "train_loss": 749.0335225805641,
          "val_loss": 4426.938184785843,
          "val_reward": 34.86882753372193
        },
        {
          "epoch": 47,
          "train_loss": 733.8097318479907,
          "val_loss": 4159.30647215388,
          "val_reward": 36.50982475280762
        },
        {
          "epoch": 48,
          "train_loss": 693.9384340472286,
          "val_loss": 4269.735000610352,
          "val_reward": 39.07130823135376
        },
        {
          "epoch": 49,
          "train_loss": 683.5260948006304,
          "val_loss": 4628.255606079101,
          "val_reward": 30.68086462020874
        }
      ]
    }
  },
  "recommendations": {
    "current_best": "GCN (production model)",
    "gat_status": "trained_but_underperformed",
    "next_steps": [
      "Tune GAT architecture for better performance",
      "Train GAT on larger dataset",
      "Integrate GAT with full hybrid trainer",
      "Test GAT with different attention mechanisms"
    ]
  }
}